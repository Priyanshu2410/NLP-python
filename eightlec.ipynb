{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "\n",
    "# doc =  nlp('''\"Let's go to N.Y.!\"''')\n",
    "\n",
    "# for sentence in doc:\n",
    "#     print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"tony gave two $ to mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tony"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokon0=doc[0]\n",
    "tokon0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokon0.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokon2=doc[2]\n",
    "tokon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokon2.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tony ==> index 0 is_alpha True is_punct False like_num: False is_currency False\n",
      "gave ==> index 1 is_alpha True is_punct False like_num: False is_currency False\n",
      "two ==> index 2 is_alpha True is_punct False like_num: True is_currency False\n",
      "$ ==> index 3 is_alpha False is_punct False like_num: False is_currency True\n",
      "to ==> index 4 is_alpha True is_punct False like_num: False is_currency False\n",
      "mary ==> index 5 is_alpha True is_punct False like_num: False is_currency False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token,\"==>\",\"index\",token.i,\n",
    "          \"is_alpha\",token.is_alpha,\n",
    "          \"is_punct\",token.is_punct,\n",
    "          \"like_num:\",token.like_num,\n",
    "          \"is_currency\",token.is_currency,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello welcome to my school \\n',\n",
       " '\\n',\n",
       " 'Name         birth day          email\\n',\n",
       " '----         ---------         -----\\n',\n",
       " 'priyanshu   24/10/2003         priyanshu226@gmail.com\\n',\n",
       " '\\n',\n",
       " 'om          25/03/2003          omlimdi262@gmail.com\\n',\n",
       " '\\n',\n",
       " 'krips       26/04/2003             kripsjaviya283@gmail.com\\n',\n",
       " '\\n',\n",
       " 'ram         27/05/2003          rampatel23gamil.com']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"school.txt\") as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello welcome to my school \\n \\n Name         birth day          email\\n ----         ---------         -----\\n priyanshu   24/10/2003         priyanshu226@gmail.com\\n \\n om          25/03/2003          omlimdi262@gmail.com\\n \\n krips       26/04/2003             kripsjaviya283@gmail.com\\n \\n ram         27/05/2003          rampatel23gamil.com'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priyanshu226@gmail.com', 'omlimdi262@gmail.com', 'kripsjaviya283@gmail.com']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "email = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        email.append(token.text)\n",
    "email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp.tokenizer.add_special_case(\"gimme\",[{ORTH:\"gim\"},{ORTH:\"me\"}])\n",
    "\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
